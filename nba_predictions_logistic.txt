# https://medium.com/analytics-vidhya/how-to-web-scrape-tables-online-using-python-and-beautifulsoup-36d5bafeb982

import requests
from bs4 import BeautifulSoup
import pandas as pd

url = 'https://www.espn.com/nba/stats/team/_/view/team/table/offensive/sort/fieldGoalPct/dir/desc"'
requests.get(url)
page = requests.get(url)

soup = BeautifulSoup(page.text, 'lxml')
# print(soup)

table_data = soup.find('table', class_ = 'Table Table--align-right')

headers = []
for i in table_data.find_all('th'):
    title = i.text
    headers.append(title)

team_names = []

team = soup.find('tbody')
for teamlogo in team.find_all('div', class_='flex items-start mr7'):
  teamname = teamlogo.find('img', class_='Image Logo Logo__sm')['title']
  team_names.append(teamname)

stats = pd.DataFrame(columns = headers)

for j in table_data.find_all('tr')[1:]:
        row_data = j.find_all('td')
        row = [tr.text for tr in row_data]
        length = len(stats)
        stats.loc[length] = row

stats.insert(0, 'team', team_names)

print(stats)

# exported current scores from 'https://www.basketball-reference.com/leagues/NBA_2022_games-november.html' to an excel csv file

# Manually upload file to google colab
from google.colab import files
uploaded = files.upload()

# read in the scores data
scores = pd.read_csv('nov_dec_scores.csv')
scores = scores.loc[0:397,:] # added for c2

scores['result_v'] = scores.iloc[:,3] - scores.iloc[:,5]

# make positive result a win for the visitor and a loss otherwise
scores.loc[scores['result_v'] > 0, 'visitor'] = 'W'
scores.loc[scores['result_v'] < 0, 'visitor'] = "L"

# make negative result v a win for the home and a loss otherwise
scores.loc[scores['result_v'] > 0, 'home'] = "W"
scores.loc[scores['result_v'] < 0, 'home'] = "L"

# Change Los Angeles Clippers to LA Clippers
scores["Visitor/Neutral"] = scores["Visitor/Neutral"].replace("Los Angeles Clippers", "LA Clippers", regex=True)
scores["Home/Neutral"] = scores["Home/Neutral"].replace("Los Angeles Clippers", "LA Clippers", regex=True)

# Make a table with only the teams, whether they were @ home and the win or loss
result1 = pd.DataFrame({'team':scores['Visitor/Neutral'],'site': 'V','result':scores['visitor']})
result2 = pd.DataFrame({'team':scores['Home/Neutral'],'site': 'H','result':scores['home']})

# combine the tables to get a probability of win based on stats
results = pd.concat([result1,result2])

# add the statistical data to the teams
merged = pd.merge(results, stats, on='team', how='left')

merged

# Select only the attributes that it makes sense to study
import numpy as np
results_stats = pd.DataFrame({'Site':merged['site'].astype("category"), 'PTS':pd.to_numeric(merged['PTS']), 'FG%':pd.to_numeric(merged['FG%']), 
                              '3P%':pd.to_numeric(merged['3P%']), 'FT%':pd.to_numeric(merged['FT%']), 'OR':pd.to_numeric(merged['OR']), 
                              'DR':pd.to_numeric(merged['DR']), 'AST':pd.to_numeric(merged['AST']), 'STL':pd.to_numeric(merged['STL']), 
                              'BLK':pd.to_numeric(merged['BLK']), 'TO':pd.to_numeric(merged['TO']), 'PF':pd.to_numeric(merged['PF']), 
                              'Result':merged['result'].astype("category")})
results_stats.Site = results_stats.Site.map({'V': 0, 'H':1})
results_stats.Result = results_stats.Result.map({'L': 0, 'W':1})

# Check for null values
is_NaN = merged.isnull()
row_has_NaN = is_NaN.any(axis=1)
rows_with_NaN = merged[row_has_NaN]
print(rows_with_NaN)

# Overall data statistics
results_stats.info()
results_stats.describe()
import matplotlib.pyplot as plt
results_stats.hist(bins=50, figsize=(20,15))
plt.show()

# Method from https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python

# cols=['Site', 'PTS', 'FG%', '3P%', 'FT%', 'OR', 'DR', 'AST', 'STL', 'BLK', 'TO', 'PF']
cols=['Site', 'FG%', '3P%', 'OR', 'AST', 'TO']

X = results_stats[cols]
y = results_stats.Result

# split X and y into training and testing sets
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)

# import the class
from sklearn.linear_model import LogisticRegression

# instantiate the model (using the default parameters)
logreg = LogisticRegression(max_iter=400) # needed to add this for the model to converge

# fit the model with data
logreg.fit(X_train,y_train)

# test the model on the test set
y_pred=logreg.predict(X_test)

# import the metrics class
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix